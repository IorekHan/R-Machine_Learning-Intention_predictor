ensemble_pred <- predict(ensemble, ensemble_test)
F1_Score(y_pred = ensemble_pred, y_true = data_over_test$Revenue, positive = "TRUE")
Accuracy(y_pred = ensemble_pred, y_true = data_over_test$Revenue)
varImpPlot(rf_model, cex = 0.7, col = "navy")
print(rf_model)
imp <- randomForest::importance(rf_model)
impvar <- rownames(imp)[order(imp[, 1], decreasing = TRUE)]
op <- par(mfrow = c(2, 3))
for (i in 1:6) { # seq_along(impvar)) { # to plot the marginal probabilities for all features
partialPlot(rf_model, data_train, impvar[i],
xlab = impvar[i],
main = paste("Partial Dependence of 'Revenue'\n on ", impvar[i])
)
}
rf_pred_train <- predict(rf_over, data_over_train)
svm_pred_train <- predict(svm_over, data_over_train)
ensemble_train <- cbind(svm_pred_train, rf_pred_train, mlp_over_pred_train_class, data_over_train$Revenue)
ensemble_train <- as.data.frame(ensemble_train)
colnames(ensemble_train) <- c("svm", "rf", "mlp", "true")
rf_pred_test <- predict(rf_over, data_over_test)
svm_pred_test <- predict(svm_over, data_over_test)
ensemble_test <- cbind(svm_pred_test, rf_pred_test, mlp_over_pred_test_class, data_over_test$Revenue)
ensemble_test <- as.data.frame(ensemble_test)
colnames(ensemble_test) <- c("svm", "rf", "mlp", "true")
ensemble <- randomForest(x = ensemble_train, y = data_over_train$Revenue, importance = TRUE, ntree = 3)
# ensemble <- ksvm(x=ensemble_train, y= data_over_train$Revenue, kernel = "vanilladot")
ensemble_pred <- predict(ensemble, ensemble_test)
F1_Score(y_pred = ensemble_pred, y_true = data_over_test$Revenue, positive = "TRUE")
Accuracy(y_pred = ensemble_pred, y_true = data_over_test$Revenue)
mlp_over_train_x <- mlp_over_train_raw_order[, 1:17]
mlp_over_train_y <- decodeClassLabels(mlp_over_train_raw_order[, 18])
mlp_over_pred_train <- predict(mlp_over, mlp_over_train_x, type = "class")
temp <- as.numeric(mlp_over_pred_train[, 2])
mlp_over_pred_train_class <- temp
mlp_over_pred_train_class[temp > 0.5] <- 1
mlp_over_pred_train_class[temp <= 0.5] <- 0
mlp_over_pred_test <- predict(mlp_over, mlp_over_test_x, type = "class")
temp <- as.numeric(mlp_over_pred_test[, 2])
mlp_over_pred_test_class <- temp
mlp_over_pred_test_class[temp > 0.5] <- 1
mlp_over_pred_test_class[temp <= 0.5] <- 0
mlp_over_pred_train_class <- mlp_over_pred_train_class == TRUE
mlp_over_pred_test_class <- mlp_over_pred_test_class == TRUE
mlp_over_pred_train_class <- as.factor(mlp_over_pred_train_class)
mlp_over_pred_test_class <- as.factor(mlp_over_pred_test_class)
rf_pred_train <- predict(rf_over, data_over_train)
svm_pred_train <- predict(svm_over, data_over_train)
ensemble_train <- cbind(svm_pred_train, rf_pred_train, mlp_over_pred_train_class, data_over_train$Revenue)
ensemble_train <- as.data.frame(ensemble_train)
colnames(ensemble_train) <- c("svm", "rf", "mlp", "true")
rf_pred_test <- predict(rf_over, data_over_test)
svm_pred_test <- predict(svm_over, data_over_test)
ensemble_test <- cbind(svm_pred_test, rf_pred_test, mlp_over_pred_test_class, data_over_test$Revenue)
ensemble_test <- as.data.frame(ensemble_test)
colnames(ensemble_test) <- c("svm", "rf", "mlp", "true")
ensemble <- randomForest(x = ensemble_train, y = data_over_train$Revenue, importance = TRUE, ntree = 3)
# ensemble <- ksvm(x=ensemble_train, y= data_over_train$Revenue, kernel = "vanilladot")
ensemble_pred <- predict(ensemble, ensemble_test)
F1_Score(y_pred = ensemble_pred, y_true = data_over_test$Revenue, positive = "TRUE")
Accuracy(y_pred = ensemble_pred, y_true = data_over_test$Revenue)
install.packages('keras')
library(keras)
install_keras()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(kableExtra)
library(xts)
library(psych)
library(corrplot)
library(caret)
library(kernlab)
library(MLmetrics)
library(RSNNS)
library(dplyr)
set.seed(1234)
# helper function
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1, 1, 2)))
par(mar = c(2, 2, 2, 2), mai = c(0.1, 0.3, 0.3, 0.3))
plot(c(139, 345), c(300, 452), type = "n", xlab = "", ylab = "", xaxt = "n", yaxt = "n")
title("CONFUSION MATRIX", cex.main = 2)
# create the matrix
rect(150, 430, 240, 370, col = "#74A0FF")
text(195, 437, "FALSE", cex = 1.2)
rect(250, 430, 340, 370, col = "#F7AD50")
text(295, 437, "TRUE", cex = 1.2)
text(138, 370, "Predicted", cex = 1.4, srt = 90, font = 2)
text(245, 448, "Actual", cex = 1.4, font = 2)
rect(150, 305, 240, 365, col = "#F7AD50")
rect(250, 305, 340, 365, col = "#74A0FF")
text(145, 400, "FALSE", cex = 1.2, srt = 90)
text(145, 335, "TRUE", cex = 1.2, srt = 90)
# add in the cm results
res <- as.numeric(cm)
text(195, 400, res[1], cex = 1.6, font = 2, col = "white")
text(195, 335, res[2], cex = 1.6, font = 2, col = "white")
text(295, 400, res[3], cex = 1.6, font = 2, col = "white")
text(295, 335, res[4], cex = 1.6, font = 2, col = "white")
}
data <- read.csv("online_shoppers_intention.csv")
data <- na.locf(data)
data_sum <- summary(data)
data_sum %>%
kable() %>%
kable_styling("striped") %>%
scroll_box(width = "700px", height = "400px")
data$OperatingSystems <- as.factor(data$OperatingSystems)
data$Browser <- as.factor(data$Browser)
data$Region <- as.factor(data$Region)
data$TrafficType <- as.factor(data$TrafficType)
data$VisitorType <- as.factor(data$VisitorType)
data$Weekend <- as.factor(data$Weekend)
data$Month <- as.factor(data$Month)
data$Revenue <- as.factor(data$Revenue)
sample_size <- floor(0.9 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = sample_size)
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
library(keras)
x_train <- to_categorical(data_train,2)
library(keras)
#x_train <- to_categorical(data_train,2)
#x_test <- to_categorical(data_test,2)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
data_train, data_train$Revenue,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
data_numeric <- data[, ]
data_numeric$Revenue <- as.integer(as.factor(data_numeric$Revenue))
data_numeric$Month <- as.integer(as.factor(data_numeric$Month))
data_numeric$Weekend <- as.integer(as.factor(data_numeric$Weekend))
data_numeric$VisitorType <- as.integer(as.factor(data_numeric$VisitorType))
data_numeric$TrafficType <- as.integer(as.factor(data_numeric$TrafficType))
data_numeric$Region <- as.integer(as.factor(data_numeric$Region))
data_numeric$Browser <- as.integer(as.factor(data_numeric$Browser))
data_numeric$OperatingSystems <- as.integer(as.factor(data_numeric$OperatingSystems))
data_numeric_train <- data_numeric[train_ind, ]
data_numeric_test <- data_numeric[-train_ind, ]
mlp_train <- data_numeric_train[sample(1:nrow(data_numeric_train), length(1:nrow(data_numeric_train))), 1:ncol(data_numeric_train)]
mlp_train_x <- mlp_train[, 1:17]
mlp_train_y <- decodeClassLabels(mlp_train[, 18])
mlp_data <- splitForTrainingAndTest(mlp_train_x, mlp_train_y, ratio = 0.1)
mlp_model <- mlp(mlp_data$inputsTrain, mlp_data$targetsTrain,
size = 40, learnFuncParams = c(0.001),
linOut = FALSE, hiddenActFunc = "Act_Logistic",
maxit = 40, inputsTest = mlp_data$inputsTest, targetsTest = mlp_data$targetsTest
)
library(keras)
#x_train <- to_categorical(data_train,2)
#x_test <- to_categorical(data_test,2)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
mlp_data$inputsTrain, mlp_data$targetsTrain,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
library(keras)
#x_train <- to_categorical(data_train,2)
#x_test <- to_categorical(data_test,2)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(17)) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
mlp_data$inputsTrain, mlp_data$targetsTrain,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
library(keras)
#x_train <- to_categorical(data_train,2)
#x_test <- to_categorical(data_test,2)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(17)) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 2, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
mlp_data$inputsTrain, mlp_data$targetsTrain,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
plot(history)
install.packages('labeling')
library(labeling)
library(labeling)
plot(history)
data_over_numeric <- data_over[, ]
data_over_numeric$Revenue <- as.factor(data_over_numeric$Revenue)
data_over_numeric$Month <- as.integer(as.factor(data_over_numeric$Month))
data_over_numeric$Weekend <- as.integer(as.factor(data_over_numeric$Weekend))
data_over_numeric$VisitorType <- as.integer(as.factor(data_over_numeric$VisitorType))
data_over_numeric$TrafficType <- as.integer(as.factor(data_over_numeric$TrafficType))
data_over_numeric$Region <- as.integer(as.factor(data_over_numeric$Region))
data_over_numeric$Browser <- as.integer(as.factor(data_over_numeric$Browser))
data_over_numeric$OperatingSystems <- as.integer(as.factor(data_over_numeric$OperatingSystems))
data_over_numeric_train <- data_over_numeric[train_ind, ]
data_over_numeric_test <- data_over_numeric[-train_ind, ]
mlp_over_train_raw_order <- data_over_numeric_train
mlp_over_train <- data_over_numeric_train[sample(1:nrow(data_over_numeric_train), length(1:nrow(data_over_numeric_train))), 1:ncol(data_over_numeric_train)]
mlp_over_train_x <- mlp_over_train[, 1:17]
mlp_over_train_y <- decodeClassLabels(mlp_over_train[, 18])
mlp_over_data <- splitForTrainingAndTest(mlp_over_train_x, mlp_over_train_y, ratio = 0.1)
# iris <- normTrainingAndTestSet(iris)
mlp_over <- mlp(mlp_over_data$inputsTrain, mlp_over_data$targetsTrain,
size = 40, learnFuncParams = c(0.001),
maxit = 150, learnFunc = "Rprop", inputsTest = mlp_over_data$inputsTest, targetsTest = mlp_over_data$targetsTest
)
mlp_over_test_x <- data_over_numeric_test[, 1:17]
mlp_over_test_y <- decodeClassLabels(data_over_numeric_test[, 18])
mlp_over_pred <- predict(mlp_over, mlp_over_test_x, type = "class")
library(keras)
#x_train <- to_categorical(data_train,2)
#x_test <- to_categorical(data_test,2)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(17)) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 2, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
mlp_over_data$inputsTrain, mlp_over_data$targetsTrain,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
library(labeling)
plot(history)
knitr::opts_chunk$set(echo = TRUE)
data_over_train <- data_over[train_ind, ]
data_over_test <- data_over[-train_ind, ]
data_over_train <- upSample(data_over_train, data_over_train$Revenue)
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(kableExtra)
library(xts)
library(psych)
library(corrplot)
library(caret)
library(kernlab)
library(MLmetrics)
library(RSNNS)
library(dplyr)
set.seed(1234)
# helper function
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1, 1, 2)))
par(mar = c(2, 2, 2, 2), mai = c(0.1, 0.3, 0.3, 0.3))
plot(c(139, 345), c(300, 452), type = "n", xlab = "", ylab = "", xaxt = "n", yaxt = "n")
title("CONFUSION MATRIX", cex.main = 2)
# create the matrix
rect(150, 430, 240, 370, col = "#74A0FF")
text(195, 437, "FALSE", cex = 1.2)
rect(250, 430, 340, 370, col = "#F7AD50")
text(295, 437, "TRUE", cex = 1.2)
text(138, 370, "Predicted", cex = 1.4, srt = 90, font = 2)
text(245, 448, "Actual", cex = 1.4, font = 2)
rect(150, 305, 240, 365, col = "#F7AD50")
rect(250, 305, 340, 365, col = "#74A0FF")
text(145, 400, "FALSE", cex = 1.2, srt = 90)
text(145, 335, "TRUE", cex = 1.2, srt = 90)
# add in the cm results
res <- as.numeric(cm)
text(195, 400, res[1], cex = 1.6, font = 2, col = "white")
text(195, 335, res[2], cex = 1.6, font = 2, col = "white")
text(295, 400, res[3], cex = 1.6, font = 2, col = "white")
text(295, 335, res[4], cex = 1.6, font = 2, col = "white")
}
data_over <- read.csv("online_shoppers_intention.csv")
data_over <- na.locf(data_over)
data_over$OperatingSystems <- as.factor(data_over$OperatingSystems)
data_over$Browser <- as.factor(data_over$Browser)
data_over$Region <- as.factor(data_over$Region)
data_over$TrafficType <- as.factor(data_over$TrafficType)
data_over$VisitorType <- as.factor(data_over$VisitorType)
data_over$Weekend <- as.factor(data_over$Weekend)
data_over$Month <- as.factor(data_over$Month)
data_over$Revenue <- as.factor(data_over$Revenue)
data_over_train <- data_over[train_ind, ]
data_over_test <- data_over[-train_ind, ]
data_over_train <- upSample(data_over_train, data_over_train$Revenue)
data_over_train <- select(data_over_train, -Class)
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(kableExtra)
library(xts)
library(psych)
library(corrplot)
library(caret)
library(kernlab)
library(MLmetrics)
library(RSNNS)
library(dplyr)
set.seed(1234)
# helper function
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1, 1, 2)))
par(mar = c(2, 2, 2, 2), mai = c(0.1, 0.3, 0.3, 0.3))
plot(c(139, 345), c(300, 452), type = "n", xlab = "", ylab = "", xaxt = "n", yaxt = "n")
title("CONFUSION MATRIX", cex.main = 2)
# create the matrix
rect(150, 430, 240, 370, col = "#74A0FF")
text(195, 437, "FALSE", cex = 1.2)
rect(250, 430, 340, 370, col = "#F7AD50")
text(295, 437, "TRUE", cex = 1.2)
text(138, 370, "Predicted", cex = 1.4, srt = 90, font = 2)
text(245, 448, "Actual", cex = 1.4, font = 2)
rect(150, 305, 240, 365, col = "#F7AD50")
rect(250, 305, 340, 365, col = "#74A0FF")
text(145, 400, "FALSE", cex = 1.2, srt = 90)
text(145, 335, "TRUE", cex = 1.2, srt = 90)
# add in the cm results
res <- as.numeric(cm)
text(195, 400, res[1], cex = 1.6, font = 2, col = "white")
text(195, 335, res[2], cex = 1.6, font = 2, col = "white")
text(295, 400, res[3], cex = 1.6, font = 2, col = "white")
text(295, 335, res[4], cex = 1.6, font = 2, col = "white")
}
data <- read.csv("online_shoppers_intention.csv")
data <- na.locf(data)
data_sum <- summary(data)
data_sum %>%
kable() %>%
kable_styling("striped") %>%
scroll_box(width = "700px", height = "400px")
data_vis <- data[, ]
col <- cor(data_vis[, c("Administrative", "Administrative_Duration", "Informational", "Informational_Duration", "ProductRelated", "ProductRelated_Duration", "BounceRates", "ExitRates", "PageValues", "SpecialDay")])
corrplot(col, method = "square", title = "Correlation Matrix for Online Shoppers Intention", tl.cex = 0.7, tl.col = "black", mar = c(1, 1, 1, 1))
pairs.panels(data_vis[c("ProductRelated", "ProductRelated_Duration")],
method = "pearson", # correlation method
hist.col = "light blue",
density = TRUE, # show density plots
)
pairs.panels(data_vis[c("BounceRates", "ExitRates")],
method = "pearson", # correlation method
hist.col = "light blue",
density = TRUE, # show density plots
)
data_vis$Month <- factor(data_vis$Month, levels = c("Feb", "Mar", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
barplot(table(data_vis$Month),
main = "Popular Shopping Month", xlab = "Month", ylab = "Count", border = "navy",
col = "light blue"
)
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(kableExtra)
library(xts)
library(psych)
library(corrplot)
library(caret)
library(kernlab)
library(MLmetrics)
library(RSNNS)
library(dplyr)
set.seed(1234)
# helper function
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1, 1, 2)))
par(mar = c(2, 2, 2, 2), mai = c(0.1, 0.3, 0.3, 0.3))
plot(c(139, 345), c(300, 452), type = "n", xlab = "", ylab = "", xaxt = "n", yaxt = "n")
title("CONFUSION MATRIX", cex.main = 2)
# create the matrix
rect(150, 430, 240, 370, col = "#74A0FF")
text(195, 437, "FALSE", cex = 1.2)
rect(250, 430, 340, 370, col = "#F7AD50")
text(295, 437, "TRUE", cex = 1.2)
text(138, 370, "Predicted", cex = 1.4, srt = 90, font = 2)
text(245, 448, "Actual", cex = 1.4, font = 2)
rect(150, 305, 240, 365, col = "#F7AD50")
rect(250, 305, 340, 365, col = "#74A0FF")
text(145, 400, "FALSE", cex = 1.2, srt = 90)
text(145, 335, "TRUE", cex = 1.2, srt = 90)
# add in the cm results
res <- as.numeric(cm)
text(195, 400, res[1], cex = 1.6, font = 2, col = "white")
text(195, 335, res[2], cex = 1.6, font = 2, col = "white")
text(295, 400, res[3], cex = 1.6, font = 2, col = "white")
text(295, 335, res[4], cex = 1.6, font = 2, col = "white")
}
data <- read.csv("online_shoppers_intention.csv")
data <- na.locf(data)
data_sum <- summary(data)
data_sum %>%
kable() %>%
kable_styling("striped") %>%
scroll_box(width = "700px", height = "400px")
data_vis <- data[, ]
col <- cor(data_vis[, c("Administrative", "Administrative_Duration", "Informational", "Informational_Duration", "ProductRelated", "ProductRelated_Duration", "BounceRates", "ExitRates", "PageValues", "SpecialDay")])
corrplot(col, method = "square", title = "Correlation Matrix for Online Shoppers Intention", tl.cex = 0.7, tl.col = "black", mar = c(1, 1, 1, 1))
pairs.panels(data_vis[c("ProductRelated", "ProductRelated_Duration")],
method = "pearson", # correlation method
hist.col = "light blue",
density = TRUE, # show density plots
)
pairs.panels(data_vis[c("BounceRates", "ExitRates")],
method = "pearson", # correlation method
hist.col = "light blue",
density = TRUE, # show density plots
)
data$OperatingSystems <- as.factor(data$OperatingSystems)
data$Browser <- as.factor(data$Browser)
data$Region <- as.factor(data$Region)
data$TrafficType <- as.factor(data$TrafficType)
data$VisitorType <- as.factor(data$VisitorType)
data$Weekend <- as.factor(data$Weekend)
data$Month <- as.factor(data$Month)
data$Revenue <- as.factor(data$Revenue)
data$OperatingSystems <- as.factor(data$OperatingSystems)
data$Browser <- as.factor(data$Browser)
data$Region <- as.factor(data$Region)
data$TrafficType <- as.factor(data$TrafficType)
data$VisitorType <- as.factor(data$VisitorType)
data$Weekend <- as.factor(data$Weekend)
data$Month <- as.factor(data$Month)
data$Revenue <- as.factor(data$Revenue)
sample_size <- floor(0.9 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = sample_size)
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
svm_model <- ksvm(Revenue ~ ., data = data_train, kernel = "vanilladot")
svm_pred <- predict(svm_model, data_test)
F1_Score(y_pred = svm_pred, y_true = data_test$Revenue, positive = "TRUE")
Accuracy(y_pred = svm_pred, y_true = data_test$Revenue)
library(nnet)
nn <- nnet(data=data_train, Revenue~.,size = 20, rang = 0.1, decay = 0.01, maxit = 1000, trControl = fitControl)
library(nnet)
nn <- nnet(data=data_train, Revenue~.,size = 10, rang = 0.1, decay = 0.01, maxit = 1000, trControl = fitControl)
library(nnet)
nn <- nnet(data=data_train, Revenue~.,size = 10, rang = 0.1, decay = 0.01, maxit = 200, trControl = fitControl)
nn_pred <- predict(nn,data_test,type="class")
#plot(nn_pred,)
nn_confusion <- confusionMatrix(as.factor(nn_pred), as.factor(data_test$Revenue))
draw_confusion_matrix(nn_confusion)
data_over <- read.csv("online_shoppers_intention.csv")
data_over <- na.locf(data_over)
data_over$OperatingSystems <- as.factor(data_over$OperatingSystems)
data_over$Browser <- as.factor(data_over$Browser)
data_over$Region <- as.factor(data_over$Region)
data_over$TrafficType <- as.factor(data_over$TrafficType)
data_over$VisitorType <- as.factor(data_over$VisitorType)
data_over$Weekend <- as.factor(data_over$Weekend)
data_over$Month <- as.factor(data_over$Month)
data_over$Revenue <- as.factor(data_over$Revenue)
data_over_train <- data_over[train_ind, ]
data_over_test <- data_over[-train_ind, ]
data_over_train <- upSample(data_over_train, data_over_train$Revenue)
data_over_train <- select(data_over_train, -Class)
svm_over <- ksvm(Revenue ~ ., data = data_over_train, kernel = "vanilladot")
svm_over_pred <- predict(svm_over, data_over_test)
F1_Score(y_pred = svm_over_pred, y_true = data_over_test$Revenue, positive = "TRUE")
Accuracy(y_pred = svm_over_pred, y_true = data_over_test$Revenue)
data_over_numeric <- data_over[, ]
data_over_numeric$Revenue <- as.factor(data_over_numeric$Revenue)
data_over_numeric$Month <- as.integer(as.factor(data_over_numeric$Month))
data_over_numeric$Weekend <- as.integer(as.factor(data_over_numeric$Weekend))
data_over_numeric$VisitorType <- as.integer(as.factor(data_over_numeric$VisitorType))
data_over_numeric$TrafficType <- as.integer(as.factor(data_over_numeric$TrafficType))
data_over_numeric$Region <- as.integer(as.factor(data_over_numeric$Region))
data_over_numeric$Browser <- as.integer(as.factor(data_over_numeric$Browser))
data_over_numeric$OperatingSystems <- as.integer(as.factor(data_over_numeric$OperatingSystems))
library(nnet)
nn.over <- nnet(data=data_over_train, Revenue~.,size = 10, rang = 0.1, decay = 0.01, maxit = 1000, trControl = fitControl)
library(nnet)
nn.over <- nnet(data=data_over_train, Revenue~.,size = 10, rang = 0.1, decay = 0.01, maxit = 200, trControl = fitControl)
nn.over.pred <- predict(nn.over,data_over_test,type="class")
#plot(nn_pred,)
nn.over.confusion <- confusionMatrix(as.factor(nn.over.pred), as.factor(data_over_test$Revenue))
draw_confusion_matrix(nn.over.confusion)
